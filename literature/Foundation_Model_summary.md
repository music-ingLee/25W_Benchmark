# Foundation Model 정리

> 이 문서는 Foundation Model의 개념과 Brain Foundation Model의 활용을 정리합니다.

---

## 1. Foundation Model이란?

### 1.1 한 문장 정의

**대규모 데이터로 미리 학습해둔 "만능 기초 모델"**

### 1.2 핵심 특징

```
Foundation Model =
  1. 대규모 데이터로 사전 학습 (Pre-training)
  2. 다양한 downstream 작업에 적용 가능
  3. 적은 추가 학습 또는 zero-shot으로 새 작업 수행
```

### 1.3 "Foundation"의 의미

```
Foundation = 기초, 토대

건물 비유:
┌─────────────────────────────┐
│  번역  │  요약  │  질의응답  │  ← 다양한 응용 (건물)
├─────────────────────────────┤
│      Foundation Model       │  ← 기초 공사 (토대)
└─────────────────────────────┘

토대가 튼튼하면 → 위에 뭘 지어도 잘 됨
```

---

## 2. 기존 AI와의 차이

### 2.1 기존 방식: 전문가 AI

```
번역 AI: 번역만 함
요약 AI: 요약만 함
챗봇 AI: 대화만 함

→ 각각 따로 만들어야 함
→ 각각 따로 학습해야 함
→ 새 작업마다 처음부터 시작
```

### 2.2 Foundation Model 방식: 만능 기초 인재

```
GPT (Foundation Model):

  대규모 텍스트로 "언어 자체"를 학습
        ↓
  언어를 이해하니까...
  ├── 번역도 됨
  ├── 요약도 됨
  ├── 대화도 됨
  └── 새로운 작업도 금방 배움
```

### 2.3 비유: 교육 과정

```
기존 AI:
  "의사 되고 싶어" → 의대 6년 (처음부터 전문 교육)
  "변호사 되고 싶어" → 로스쿨 3년 (처음부터 전문 교육)
  → 각각 따로 처음부터 배움

Foundation Model:
  "일단 대학 교양 4년" → 세상 전반에 대해 배움
  → 그 후 의대 1년 추가 → 의사
  → 또는 로스쿨 1년 추가 → 변호사
  → 기초가 있으니 전문화가 빠름
```

---

## 3. 흔한 오해 바로잡기

### 3.1 오해: "여러 종류의 데이터를 다루면 Foundation Model"

```
잘못된 이해:
  이미지 잘 분류 → 텍스트도 잘 분류 → 청각도 잘 분류
  = Foundation Model?

이건 "멀티모달(Multimodal)" 모델이지, Foundation Model의 정의는 아님.
```

### 3.2 정확한 이해

```
Foundation Model의 핵심:
  "같은 종류의 데이터"로 "여러 작업" 수행

예: GPT (텍스트 Foundation Model)
├── 번역 (한국어 → 영어)
├── 요약 (긴 글 → 짧게)
├── 질의응답 (질문 → 답변)
├── 코드 작성
└── ... (전부 "텍스트" 데이터, 하지만 "작업"이 다양)
```

---

## 4. 대표적 Foundation Model들

| 모델 | 학습 데이터 | 학습 목표 | 할 수 있는 작업들 |
|------|------------|----------|------------------|
| GPT | 텍스트 | 다음 단어 예측 | 번역, 요약, 대화, 코딩... |
| BERT | 텍스트 | 빈칸 채우기 | 분류, 질의응답... |
| CLIP | 이미지+텍스트 | 짝 맞추기 | 검색, 분류, 캡셔닝... |
| Whisper | 오디오 | 음성→텍스트 | 음성인식, 번역... |
| SAM | 이미지 | 영역 분할 | 객체 분할, 영역 선택... |

---

## 5. Pre-training과 Fine-tuning

### 5.1 두 단계 구조

```
┌─────────────────────────────────────────────────────┐
│  1단계: Pre-training (사전 학습)                     │
│                                                      │
│  • 대규모 데이터로 학습                              │
│  • "일반적인 패턴" 학습                              │
│  • Foundation Model 완성                            │
│                                                      │
│  예: 인터넷 텍스트 수조 개로 "언어" 학습             │
└─────────────────────────────────────────────────────┘
                         ↓
┌─────────────────────────────────────────────────────┐
│  2단계: Fine-tuning (미세 조정)                      │
│                                                      │
│  • 특정 작업에 맞게 추가 학습                        │
│  • 적은 데이터로도 가능                              │
│  • Cross-validation으로 train/test 나눔             │
│                                                      │
│  예: "감정 분류" 작업에 맞게 조정                    │
└─────────────────────────────────────────────────────┘
```

### 5.2 Fine-tuning 더 깊이 이해하기: GPT 예시

#### 흔한 오해

```
GPT가 법률, 의학, 심리, 코딩 다 잘 대답하니까...
→ 각 분야별로 Fine-tuning을 무한대로 했다?

❌ 아니야!
✓ Pre-training 자체가 워낙 방대해서 이미 다 "알고 있는" 상태
```

#### Pre-training의 규모

```
GPT가 Pre-training에서 본 것:
├── 위키피디아 전체 (모든 언어)
├── 수백만 권의 책
├── 뉴스 기사 수억 개
├── GitHub 코드 수억 줄
├── 의학 논문, 법률 문서
├── Stack Overflow 질문/답변
└── ... (상상 가능한 거의 모든 것)

데이터 크기: 수조 개의 단어
→ Pre-training에서 이미 법률, 의학, 코딩을 "읽었음"
```

#### ChatGPT의 Fine-tuning은 뭘 한 거야?

```
Pre-trained GPT:
  • 모든 지식을 가지고 있음
  • 하지만 "대화체"로 대답하는 법을 모름

  Q: "파이썬이 뭐야?"
  A: "파이썬은 1991년 귀도 반 로섬이 개발한..." (위키피디아처럼)

Fine-tuned GPT (ChatGPT):
  • "친절하게 대화하는 법"만 추가 학습 (RLHF)
  • 지식 자체는 이미 있음

  Q: "파이썬이 뭐야?"
  A: "파이썬은 배우기 쉬운 프로그래밍 언어예요!
      어떤 걸 만들고 싶으신지 알려주시면 도움 드릴게요."
```

#### 비유: 백과사전 vs 선생님

```
Pre-trained GPT = 모든 책을 읽은 사람
  • 지식은 있지만, 잘 설명하는 법은 모름

Fine-tuned GPT = 선생님 교육 받은 사람
  • 지식은 그대로 + "학생에게 친절하게 설명하는 법" 추가
```

#### Zero-shot: Fine-tuning 없이 바로 수행

```
GPT에게 처음 보는 작업 요청:

"이 계약서의 법적 위험성을 분석해줘"
→ 법률 Fine-tuning 없이도 대답 가능
   (Pre-training에서 법률 문서를 봤으니까)

이것이 Zero-shot의 힘!
```

#### 그럼 Fine-tuning은 언제 필요해?

| 상황 | Fine-tuning 필요? |
|------|------------------|
| 일반적인 질문 응답 | ❌ Pre-training으로 충분 |
| 특수한 말투/형식 필요 | ✓ (예: 우리 회사 스타일) |
| Pre-training에 없는 데이터 | ✓ (예: 비공개 내부 문서) |
| 성능을 더 높이고 싶을 때 | ✓ (예: 법률 전문 AI) |

#### 시각적 정리

```
┌─────────────────────────────────────────────────┐
│              Pre-training (거대함)               │
│                                                  │
│   법률 ███████████████                          │
│   의학 ███████████████                          │
│   코딩 ███████████████                          │
│   ... (거의 모든 분야)                           │
└─────────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────┐
│         Fine-tuning (작음, 대화법만)             │
│                                                  │
│   "친절하게 대화하는 법" ██                      │
└─────────────────────────────────────────────────┘
                      ↓
                   ChatGPT
        (모든 분야 + 친절한 대화)
```

### 5.3 Cross-Validation은 어디에?

```
Pre-training:
  • 데이터가 워낙 많아서 (수만~수백만)
  • 보통 단순히 train/validation/test로 나눔
  • Cross-validation은 잘 안 씀 (계산 비용 너무 큼)

Fine-tuning:
  • 데이터가 상대적으로 적음
  • Cross-validation으로 과적합 방지
  • 일반화 성능 평가
```

---

## 6. Brain Foundation Model

### 6.1 정의

**대규모 뇌 데이터(fMRI 등)로 미리 학습해둔 "뇌 해석 기초 모델"**

```
일반 Foundation Model: 이미지/텍스트 → 벡터
Brain Foundation Model: 뇌 활동(fMRI, EEG) → 벡터
```

### 6.2 왜 필요한가?

```
문제:
  • fMRI 데이터는 비싸고, 시간 오래 걸림
  • 연구마다 피험자 수~수십 명 수준
  • 각 연구가 독립적, 일반화 어려움

해결책:
  • 여러 연구 데이터를 통합
  • Foundation Model로 "뇌 활동의 일반 패턴" 학습
  • 새 작업에 적은 데이터로 빠르게 적용
```

### 6.3 학습 방식들

#### 방식 1: CLIP처럼 "짝 맞추기"

```
fMRI 데이터 ←→ 그때 본 이미지 (또는 CLIP 벡터)

학습:
  [고양이 볼 때 fMRI] ↔ [고양이 사진] → 정답, 가깝게!
  [고양이 볼 때 fMRI] ↔ [비행기 사진] → 오답, 멀게!
```

#### 방식 2: BERT처럼 "가린 부분 예측"

```
fMRI의 일부를 가리고, 나머지로 가린 부분 예측

학습:
  [시각피질 활동] + [???] + [전두엽 활동]
  → "???" 부분은 뭘까? 예측해봐
```

#### 방식 3: GPT처럼 "다음 시점 예측"

```
t=1초 fMRI → t=2초 fMRI → t=3초 fMRI → ???

학습:
  "다음 시점의 뇌 활동은 어떨까?"
```

### 6.4 할 수 있는 작업들 (Downstream Tasks)

```
Brain Foundation Model (사전 학습 완료)
           ↓
    ┌──────┴──────┬──────────┬──────────┐
    ↓             ↓          ↓          ↓
 뇌 디코딩    뇌 인코딩    질환 진단   개인차 분석
```

| 작업 | 설명 | 예시 |
|------|------|------|
| 뇌 디코딩 | fMRI → 본 것/생각 추론 | "이 사람은 고양이를 보고 있다" |
| 뇌 인코딩 | 자극 → 뇌 반응 예측 | "고양이 보면 시각피질 여기가 활성화" |
| 질환 진단 | fMRI → 질환 분류 | "알츠하이머 초기 징후 있음" |
| 개인차 분석 | fMRI → 개인 특성 | "IQ 추정: 120" |

---

## 7. CLIP과 Brain Foundation Model의 연결

### 7.1 왜 CLIP을 활용하나?

```
직접 재구성의 어려움:
  뇌 활동 → 이미지 (픽셀 수백만 개)
  → 너무 어려움

CLIP 활용:
  뇌 활동 → CLIP 벡터 (512개) → 이미지
  → 512개만 예측하면 됨
  → CLIP이 "의미"를 압축해서 담고 있음
```

### 7.2 학습 과정

```
1. 데이터 수집:
   피험자가 이미지 1000장을 보는 동안 fMRI 측정

2. CLIP 벡터 준비:
   각 이미지의 CLIP 벡터는 미리 알고 있음

3. 예측 모델 학습:
   뇌 활동 → CLIP 벡터 예측
   틀리면 파라미터 수정 (Ridge 또는 딥러닝)

4. 학습 완료 후:
   새 fMRI → CLIP 벡터 추정 → 가장 비슷한 이미지 찾기
```

### 7.3 실제 연구 사례

| 모델 | 학습 방식 | 특징 |
|------|----------|------|
| MindEye (2023) | fMRI ↔ CLIP 벡터 매칭 | 고품질 이미지 재구성 |
| Mind-Vis (2023) | fMRI → 이미지 생성 | Stable Diffusion 활용 |
| BrainLM | fMRI 패턴 예측 | 대규모 데이터 활용 |

---

## 8. 전체 비교 정리

| | GPT | CLIP | Brain FM |
|--|-----|------|----------|
| 학습 데이터 | 텍스트 | 이미지+텍스트 | fMRI |
| 학습 목표 | 다음 단어 예측 | 짝 맞추기 | 다양 (짝 맞추기, 예측 등) |
| 결과 | 언어 이해 | 시각-언어 연결 | 뇌 활동 이해 |
| 응용 | 번역, 요약, 대화... | 검색, 분류... | 디코딩, 진단... |
| 성숙도 | 매우 높음 | 높음 | 초기 단계 |

---

## 9. Horikawa (2020)의 한계에서 보는 Foundation Model의 필요성

### 9.1 Horikawa 연구 개요

```
피험자: 5명
자극: 2,185개 비디오
분석: Ridge Regression (개별 피험자별로)
결과: 감정 디코딩/인코딩 성공
```

### 9.2 한계점 1: 피험자 수가 적다

```
5명의 뇌가 비슷하게 반응한다고 해서...
→ 모든 인간이 그런가?
→ 6번째 사람에게도 적용될까?

새로운 피험자 A가 참여:
  Horikawa 모델: "이 사람의 fMRI 패턴, 처음 보는데?"
                → 처음부터 다시 학습해야 함
                → 또 수천 장 자극 보여줘야 함

Foundation Model이 있다면?
  "수천 명의 뇌 패턴을 이미 배웠어"
  → 새 피험자도 금방 적응
  → 적은 데이터로 Fine-tuning
```

### 9.3 한계점 2: 개별 모델, 일반화 어려움

```
Horikawa 연구 구조:
  피험자1 데이터 → 피험자1 전용 모델
  피험자2 데이터 → 피험자2 전용 모델
  ...
  → 5개의 분리된 모델
  → 공통 패턴 활용 못함

Foundation Model 구조:
  피험자 1~1000명 데이터 → Foundation Model (공통 패턴 학습)
                              ↓
                    새 피험자에게 Fine-tuning
```

### 9.4 한계점 3: 새로운 자극에 취약

```
Horikawa 연구:
  학습/테스트: 같은 종류의 비디오
  완전히 새로운 자극 → 제대로 예측할 수 있을까?

Foundation Model:
  수만 가지 자극으로 사전 학습
  → "처음 보는 자극"에도 일반화 가능
```

### 9.5 한계점 4: 다른 연구와 연결 어려움

```
현실:
  Horikawa 연구: 감정 + 비디오 + 5명
  다른 연구 A: 얼굴 인식 + 이미지 + 20명
  다른 연구 B: 언어 처리 + 단어 + 15명
  → 각 연구가 독립적, 통합 어려움

Foundation Model이 있다면:
  모든 연구 데이터 → Foundation Model
  → 공통 기반 위에서 다양한 연구 가능
```

### 9.6 한계점 5: 선형 모델의 한계

```
Ridge Regression:
  장점: 해석 가능, 계산 빠름
  단점: 비선형 패턴 포착 못함 (직선만 그릴 수 있음)

Foundation Model (딥러닝 기반):
  장점: 복잡한 패턴 포착 가능
  단점: 데이터 많이 필요 → 대규모 Pre-training으로 해결
```

### 9.7 정리: 한계 → 필요성

| Horikawa의 한계 | Foundation Model의 해결 |
|----------------|------------------------|
| 피험자 5명 | 수천 명 데이터 통합 |
| 개별 모델 | 공통 모델 + Fine-tuning |
| 특정 자극에 한정 | 다양한 자극으로 일반화 |
| 다른 연구와 단절 | 통합 기반 제공 |
| 선형 모델 한계 | 비선형 딥러닝 가능 |

### 9.8 그럼에도 Horikawa 연구의 가치

```
Foundation Model이 없던 2020년에:
  • 5명으로도 의미있는 결과
  • 감정의 신경 표상 구조 밝힘
  • 카테고리 > 차원 모델 증거 제시

→ 이런 연구들이 쌓여야 Foundation Model도 가능
→ Foundation Model의 "필요성"을 보여준 선구적 연구
```

---

## 10. 핵심 용어 정리

| 용어 | 설명 |
|------|------|
| Foundation Model | 대규모 데이터로 사전 학습한 범용 모델 |
| Pre-training | 대규모 데이터로 일반 패턴 학습 (Foundation Model 생성) |
| Fine-tuning | 특정 작업에 맞게 추가 학습 |
| Downstream Task | Foundation Model을 활용해 수행하는 구체적 작업 |
| Brain Foundation Model | 대규모 뇌 데이터로 학습한 뇌 해석 모델 |
| Zero-shot | Fine-tuning 없이 바로 새 작업 수행 |

---

*마지막 업데이트: 2026-01-07*
