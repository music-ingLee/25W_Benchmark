# Cowen & Keltner (2017) PNAS 정리노트

> **논문 제목**: Self-report captures 27 distinct categories of emotion bridged by continuous gradients
> **저널**: PNAS, 2017
> **저자**: Alan S. Cowen, Dacher Keltner (UC Berkeley)

---

## 목차

1. [핵심 연구 질문](#1-핵심-연구-질문)
2. [실험 설계](#2-실험-설계)
3. [34개 카테고리의 출처와 27개로의 축소](#3-34개-카테고리의-출처와-27개로의-축소)
4. ["예측"과 "학습"의 기초 개념](#4-예측과-학습의-기초-개념)
5. [예측: 카테고리 vs 차원 비교](#5-예측-카테고리-vs-차원-비교)
6. [왜 "카테고리적"이라는 결론인가?](#6-왜-카테고리적이라는-결론인가)
7. [연속적 그라디언트](#7-연속적-그라디언트)
8. [최종 결론](#8-최종-결론)

---

## 1. 핵심 연구 질문

> **"감정의 주관적 경험(self-report)은 어떤 구조로 조직되어 있는가?"**

### 기존 이론의 대립

| 이론 | 핵심 주장 | 대표 학자 |
|:-----|:---------|:---------|
| **Basic Emotion Theory** | 6~15개 기본 감정이 별개의 클러스터로 존재 | Ekman |
| **Dimensional Theory** | valence-arousal 연속 차원으로 모든 감정 설명 | Russell |

---

## 2. 실험 설계

### 2.1 전체 구조

```
총 비디오:           2,185개
총 참가자:           853명 (Amazon Mechanical Turk)
비디오당 평정 횟수:   9~17회
```

### 2.2 Between-subjects + Random Sampling

> **핵심**: 한 사람이 2,185개를 전부 보는 게 아니다!

| 조건 | 과제 | 1인당 비디오 수 |
|:-----|:-----|:---------------|
| 그룹 1 | 자유 응답 (Free Response) | 30개 |
| 그룹 2 | 34개 카테고리 평정 | 30개 |
| 그룹 3 | 14개 차원 평정 | 12개 |

### 2.3 랜덤 샘플링의 의미

각 참가자가 본 30개는 **고정된 세트가 아님**:

```
참가자 A (자유응답): 비디오 #5, #23, #156, #789...  (랜덤 30개)
참가자 B (자유응답): 비디오 #12, #45, #234, #567... (다른 랜덤 30개)
참가자 C (카테고리): 비디오 #5, #78, #234, #999...  (또 다른 랜덤 30개)
```

> **왜 이렇게?**
> - 2,185개 × 5초 = 약 3시간 → 피로, 집중력 저하 방지
> - 랜덤 샘플링으로 **모든 비디오**가 **모든 조건**에서 평정받음

---

## 3. 34개 카테고리의 출처와 27개로의 축소

### 3.1 흔한 오해

> ~~"자유응답에서 34개 카테고리를 도출하고, 이를 27개로 축소했다"~~

**실제 순서는 다르다!**

### 3.2 34개 카테고리: 이론에서 사전 도출

34개는 **기존 감정 이론들을 종합**해서 연구자들이 **미리 선정**한 목록:

> *"The 34 emotion categories were derived from emotion taxonomies of prominent theorists; recent studies of positive emotions; Darwin's observations..."*

**출처**:
- 기존 감정 분류 체계 (Ekman, Russell 등)
- 긍정 감정 연구 (awe, joy, love, desire, excitement)
- 다윈의 관찰 (admiration, adoration, sympathy)
- 일상 상호작용 연구 (confusion, awkwardness, calmness)

### 3.3 세 조건의 역할

| 조건 | 역할 |
|:-----|:-----|
| **카테고리 평정** | 34개 카테고리로 각 비디오 평정 → **주요 분석 데이터** |
| **자유 응답** | 사람들이 실제로 쓰는 단어 확인 → **검증 (Validation)** |
| **차원 평정** | 14개 차원 (valence, arousal 등) → **카테고리 vs 차원 비교** |

### 3.4 34개 → 27개 축소 과정

```
34개 카테고리 (이론에서 도출)
         ↓
카테고리 평정 데이터 수집 (2,185 비디오 × 9~17명)
         ↓
통계 분석 (SH-CCA, PCA + Varimax Rotation)
         ↓
27개만 "신뢰롭게 구분됨" (reliably separable)
```

**탈락한 7개**: `contempt`, `disappointment`, `envy`, `guilt`, `relief`, `sympathy`, `triumph`

- 다른 카테고리와 동의어처럼 사용됨 (예: pride ≈ triumph)
- 또는 일관되게 평정되지 않음 (예: envy, guilt)

### 3.5 자유응답의 역할: 도출이 아닌 검증

자유응답은 27개를 **"도출"**한 게 아니라 **"검증"**한 것:

> *"we found 27 significant linearly independent patterns of shared variance between the categorical and free response reports"*

**질문**: 카테고리 평정에서 나온 27개 구분이 자유응답에서도 나타나는가?
**답**: **Yes!** → **Convergent Validity** (수렴 타당도) 확보

---

## 4. "예측"과 "학습"의 기초 개념

논문에서 말하는 "예측(prediction)"은 머신러닝인가? 복잡한 딥러닝이 아니라, **회귀 분석(regression)**의 확장이다.

### 4.1 "예측"이란?

#### 일상적 의미
> "내일 비가 올 것이다" → 미래를 맞추는 것

#### 통계/머신러닝에서의 의미
> "A를 알면 B를 맞출 수 있는가?" → **관계를 학습해서 추정하는 것**

```
예측 = "이미 알고 있는 정보(A)로 모르는 정보(B)를 추정"
```

### 4.2 가장 쉬운 예시: 키와 몸무게

#### 데이터

| 사람 | 키 (cm) | 몸무게 (kg) |
|:-----|:--------|:-----------|
| A | 160 | 55 |
| B | 170 | 65 |
| C | 180 | 75 |
| D | 175 | 70 |

#### "예측 모델"을 만든다는 것

```
키 → [모델] → 몸무게 예측

모델이 학습한 것: "키가 10cm 늘면 몸무게가 약 10kg 는다"
```

#### 새로운 사람 E (키 165cm)가 오면?

```
165cm → [모델] → "약 60kg일 것이다" (예측)
```

### 4.3 "학습"이란?

> **데이터에서 패턴(규칙)을 찾아내는 것**

#### 수학적으로

```
모델: y = ax + b

학습 = a와 b 값을 찾는 것

데이터를 보고:
"a = 1, b = -105일 때 오차가 가장 작네!"

→ 학습 완료: y = 1x - 105 (= 몸무게 = 키 - 105)
```

#### 비유: 시험 공부

```
학습 = 문제집으로 공부 (패턴 파악)
모델 = 공부해서 얻은 "풀이법"
테스트 = 처음 보는 문제로 시험
예측 = 시험 답안
```

### 4.4 데이터포인트란?

비디오 2,184개로 모델을 만든다면, 비디오마다 회귀식이 나오는 것인가?

**아니다!** 비디오 1개 = **데이터포인트 1개** (회귀식을 만드는 "재료")

#### 잘못된 이해

```
비디오 1 → 회귀식 1
비디오 2 → 회귀식 2
...
비디오 2184 → 회귀식 2184  (❌)
```

#### 올바른 이해

```
비디오 1    ─┐
비디오 2    ─┼─→ 2,184개 점을 모아서 → 회귀식 1개  (✓)
비디오 3    ─┤
...         │
비디오 2184 ─┘
```

#### 키-몸무게로 비유

```
     몸무게
        │      ● D (175, 70)
        │    ● C (180, 75)
        │  ● B (170, 65)
        │● A (160, 55)
        └──────────────── 키

4개 점 → 4개 회귀식? (❌)
4개 점 → 이 점들을 관통하는 선 1개 (✓)
```

**핵심**: 점 1개로는 선을 못 그린다. 여러 점을 모아야 "가장 잘 맞는 선"을 찾을 수 있다.

### 4.5 서로 다른 길이의 벡터와 데이터포인트

차원 벡터(14개)와 카테고리 벡터(34개)의 길이가 다른데, 어떻게 하나의 데이터포인트가 되는가?

**데이터포인트 = (입력, 출력) 쌍.** 길이가 달라도 됨!

#### 엑셀 테이블로 생각

```
         입력 (2개)          출력 (1개)
        ┌─────┬─────┐      ┌────────┐
        │ 키  │ 나이 │      │ 몸무게  │
├───────┼─────┼─────┼──────┼────────┤
│ 사람A │ 160 │ 25  │  →   │   55   │   ← 데이터포인트 1개
│ 사람B │ 170 │ 30  │  →   │   65   │   ← 데이터포인트 1개
│ 사람C │ 180 │ 35  │  →   │   75   │   ← 데이터포인트 1개
└───────┴─────┴─────┴──────┴────────┘

입력 2개, 출력 1개 → 길이 다름. 하지만 한 줄 = 데이터포인트 1개
```

#### Cowen 연구에서

```
          입력 (14개)                    출력 (1개)
        ┌────────────────────────┐     ┌──────┐
        │ valence, arousal, ...  │     │ fear │
├───────┼────────────────────────┼─────┼──────┤
│ 비디오1│  -0.7,   0.9,  ...    │  →  │ 0.8  │  ← 데이터포인트 1개
│ 비디오2│   0.5,   0.3,  ...    │  →  │ 0.1  │  ← 데이터포인트 1개
└───────┴────────────────────────┴─────┴──────┘
```

### 4.6 다중 회귀 (Multiple Regression)

입력이 14개인 경우 어떻게 회귀를 하는가?

#### 단순 회귀

```
x (1개) → y (1개)

예: 키 → 몸무게
수식: y = ax + b
```

#### 다중 회귀 (입력 여러 개)

```
x₁, x₂, x₃... (여러 개) → y (1개)

예: 키, 나이, 운동량 → 몸무게
수식: y = a₁x₁ + a₂x₂ + a₃x₃ + b
```

#### Cowen에서 fear 예측

```
차원 14개 → fear 1개

fear = a₁(valence) + a₂(arousal) + ... + a₁₄(certainty) + b
```

#### 시각화 관점

- 입력 **1개** → 출력 1개: **선 (2D)**
- 입력 **2개** → 출력 1개: **평면 (3D)**
- 입력 **14개** → 출력 1개: **14차원 초평면** (시각화 불가, but 수학은 동일)

### 4.7 출력이 여러 개면? (카테고리 34개)

카테고리가 34개라면 회귀식은 몇 개인가?

**각 카테고리마다 별도 회귀식!**

```
차원 (14개) → fear   : 회귀식 1
차원 (14개) → joy    : 회귀식 2
차원 (14개) → anger  : 회귀식 3
...
차원 (14개) → awe    : 회귀식 34

→ 총 34개 모델
```

### 4.8 Cross-Validation (교차 검증)

그냥 회귀만 돌리면 되는 것 아닌가?

**문제**: 학습에 쓴 데이터로 테스트하면 "시험 문제 미리 본 것"

```
전체 데이터로 학습 → 전체 데이터로 테스트 → 과적합 위험!
```

**해결**: Leave-One-Out Cross-Validation

```
Round 1: 비디오 #2~#2185로 학습 → #1로 테스트 → 오차 계산
Round 2: 비디오 #1, #3~#2185로 학습 → #2로 테스트 → 오차 계산
...
Round 2185: 비디오 #1~#2184로 학습 → #2185로 테스트 → 오차 계산

→ 2,185개 오차의 평균 = 최종 예측 성능
```

**비유**:

```
나쁜 방법: 시험 문제 미리 보고 시험 → "100점!" (진짜 실력? 모름)
좋은 방법: 처음 보는 문제로 시험 → "78점" (진짜 예측력 확인)
```

### 4.9 Cowen이 실제로 사용한 방법

| 요소 | 사용한 것 |
|:-----|:---------|
| **회귀 종류** | Linear Regression + k-Nearest Neighbors (둘 다) |
| **검증 방법** | Leave-One-Out Cross-Validation |
| **성능 지표** | 설명 가능한 분산 대비 비율 |

**왜 두 가지 회귀?** 선형 관계가 아닐 수도 있으니 비선형(kNN)도 확인
**결과**: 둘 다 비슷한 패턴 → 결론이 견고함

---

## 5. 예측: 카테고리 vs 차원 비교

### 5.1 핵심 질문

> 감정 경험을 설명할 때, **카테고리**(fear, joy...)가 더 유용한가,
> **차원**(valence, arousal...)이 더 유용한가?

### 5.2 예측의 두 방향

#### 방향 1: 차원 → 카테고리

```
입력: 14개 차원 점수 (valence, arousal, dominance...)
         ↓
      회귀 모델 (34개, 카테고리마다 1개)
         ↓
출력: 34개 카테고리 점수 예측
```

> "이 비디오가 valence=-0.8, arousal=0.9라면, fear인지 anger인지 맞출 수 있나?"

#### 방향 2: 카테고리 → 차원

```
입력: 34개 카테고리 점수 (fear=0.9, joy=0.1, awe=0.2...)
         ↓
      회귀 모델 (14개, 차원마다 1개)
         ↓
출력: 14개 차원 점수 예측
```

> "이 비디오가 fear=0.9라면, valence와 arousal을 맞출 수 있나?"

### 5.3 결과

| 예측 방향 | 설명된 분산 |
|:----------|:-----------|
| **카테고리 → 차원** | **78%** |
| **차원 → 카테고리** | **61%** |

> **카테고리가 차원을 더 잘 예측한다!**

---

## 6. 왜 "카테고리적"이라는 결론인가?

### 6.1 핵심 논리: "무엇이 더 기본적인가?"

#### 만약 차원이 진짜 기본이라면?

```
차원 (기본, 모든 정보 포함)
  ↓
카테고리 (차원의 조합, 파생물)
```

이 경우:
- 차원 → 카테고리 예측이 **거의 완벽**해야 함
- 원본(차원)이 복사본(카테고리)을 다 설명해야 하니까

#### 실제 결과는?

```
차원 → 카테고리: 61%  ← 뭔가 빠졌다!
카테고리 → 차원: 78%
```

> **차원이 카테고리를 다 설명 못 함**
> = 카테고리에는 차원이 담지 못하는 **추가 정보**가 있다

### 6.2 비유: 원본과 요약본

| 차원 이론의 예측 | 실제 결과 |
|:----------------|:---------|
| 차원 = 원본, 카테고리 = 요약본 | 카테고리가 더 풍부한 정보 보유 |
| 원본 → 요약본 예측 ≈ 100% | 61%밖에 설명 못 함 |
| 요약본 → 원본 예측 < 100% | 오히려 78%로 더 높음 |

> **결론**: 차원이 "원본"이 아니었다.
> 감정 경험의 **심리적 실재(psychological reality)**가 카테고리에 더 가깝다.

### 6.3 구체적 예시: fear vs anger

```
           valence (-)
               ↑
               |
       fear ●  |  ● anger    ← 둘 다 negative valence + high arousal
               |
      ─────────┼─────────→ arousal (+)
               |
```

- **차원만 알면**: fear인지 anger인지 구분 불가
- **카테고리를 알면**: 대략적인 차원 위치는 추정 가능

---

## 7. 연속적 그라디언트

### 7.1 겉보기 모순

> "카테고리가 중요하다" + "연속적 그라디언트가 있다"
> → 카테고리면 딱딱 구분되어야 하는 거 아닌가?

### 7.2 Basic Emotion Theory의 예측

```
[fear]     [anger]     [joy]     [sadness]
   ●          ●          ●          ●

→ 각 감정이 별개의 클러스터로 "뚝뚝" 떨어져 있음
```

### 7.3 Cowen이 실제로 발견한 것

```
anxiety ━━━━ fear ━━━━ horror ━━━━ disgust
   ●━━━━━━━━━●━━━━━━━━━●━━━━━━━━━●

→ 카테고리는 있지만, 사이사이가 연결되어 있음
```

### 7.4 구체적 증거

| 카테고리 쌍 | 같은 비디오에 의해 유발된 횟수 | 해석 |
|:-----------|:----------------------------|:----|
| anxiety + fear | 75회 | 인접 |
| fear + horror | 55회 | 인접 |
| anxiety + horror | 8회 | 멀리 떨어짐 |

> **징검다리처럼 연결된 구조**: 인접한 카테고리끼리는 겹치지만, 먼 카테고리끼리는 거의 안 겹침

### 7.5 비유: 색깔 스펙트럼

```
Basic emotion 예측:  빨강 ■    주황 ■    노랑 ■    (별개의 페인트통)

Cowen 발견:          빨강 ■■■■ 주황 ■■■■ 노랑      (그라디언트 스펙트럼)
```

> 하지만 여전히 "빨강", "주황"이라는 **카테고리 이름**은 유용함

### 7.6 두 극단 모두 틀렸다

| 이론 | 주장 | Cowen의 판정 |
|:-----|:-----|:------------|
| **Basic Emotion** | 6개 감정이 완전히 별개로 존재 | ❌ 경계가 fuzzy |
| **Dimensional** | 연속적 valence-arousal 공간만 존재 | ❌ 카테고리 구조 있음 |
| **Cowen** | 카테고리 + 연속적 그라디언트 **둘 다** | ✓ |

---

## 8. 최종 결론

> **"감정은 카테고리적이지만, 카테고리들 사이의 경계는 칼로 자른 듯 명확하지 않고 연속적으로 이어져 있다"**

```
카테고리의 존재   → Yes (차원보다 설명력 높음)
카테고리의 경계   → Fuzzy (discrete하지 않음)
카테고리의 개수   → 27개 (기존 이론의 6~15개보다 풍부)
```

---

## 참고 자료

- **Interactive Map**: https://s3-us-west-1.amazonaws.com/emogifs/map.html
- **원문**: Cowen, A. S., & Keltner, D. (2017). Self-report captures 27 distinct categories of emotion bridged by continuous gradients. *PNAS*, 114(38), E7900-E7909.

---

*마지막 업데이트: 2026-01-04*
