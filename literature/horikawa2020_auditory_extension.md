# Horikawa (2020) 연구의 청각 모달리티 확장 가능성

> **원 연구**: Horikawa et al. (2020) - 시각 자극(무음 비디오)을 통한 감정의 신경 표상 연구
> **핵심 발견**: 감정은 고차원적, 카테고리적, Transmodal 영역에 분산 표상됨

---

## 목차

1. [왜 청각 모달리티로 확장해야 하는가?](#1-왜-청각-모달리티로-확장해야-하는가)
2. [청각 자극의 종류](#2-청각-자극의-종류)
3. [일반 청각 자극으로의 확장](#3-일반-청각-자극으로의-확장)
4. [음악 자극으로의 확장](#4-음악-자극으로의-확장)
5. [비교 요약](#5-비교-요약)
6. [결론 및 제언](#6-결론-및-제언)

---

## 1. 왜 청각 모달리티로 확장해야 하는가?

### 1.1 현재 연구의 한계

```
Horikawa (2020):
  입력: 시각 자극 (무음 비디오)
  발견: Transmodal 영역에서 감정 인코딩

남은 질문:
  "이게 '시각적 감정'만의 특성인가?"
  "아니면 '감정 일반'의 특성인가?"

→ 시각 자극만으로는 구분 불가
```

### 1.2 확장의 이론적 의의

```
가능한 결과 1: 수렴 (Convergence)
┌─────────────────────────────────────────────────────────┐
│  시각 자극 → Transmodal 영역에서 카테고리적 표상          │
│  청각 자극 → Transmodal 영역에서 카테고리적 표상          │
│                                                         │
│  결론: 감정의 카테고리 구조는 모달리티 독립적!            │
│       → 매우 강력한 이론적 주장 가능                     │
└─────────────────────────────────────────────────────────┘

가능한 결과 2: 분리 (Divergence)
┌─────────────────────────────────────────────────────────┐
│  시각 자극 → 영역 A에서 카테고리적 표상                   │
│  청각 자극 → 영역 B에서 차원적 표상                      │
│                                                         │
│  결론: 감정 표상은 모달리티에 따라 다름                   │
│       → 이것도 중요한 발견!                             │
└─────────────────────────────────────────────────────────┘
```

### 1.3 Horikawa 연구가 제공하는 힌트

논문에서 저자들이 직접 언급:

> "These stimuli are still only visual in nature. Future studies could build on this work by including auditory content" (p.16)

또한, 감정 표상이 **Transmodal 영역**에 집중된다는 발견은 청각 자극으로도 같은 영역이 활성화될 가능성을 시사함.

---

## 2. 청각 자극의 종류

```
청각을 통한 감정 유발 방식:

1. 비언어적 발성 (Nonverbal Vocalization)
   - 웃음, 울음, 비명, 한숨, 신음
   - 언어 의미 없이 순수 청각-감정 연결

2. 음성 톤/운율 (Speech Prosody)
   - 같은 문장, 다른 감정 톤
   - "괜찮아" (진심 vs 화남 vs 슬픔)

3. 환경음/효과음 (Environmental Sounds)
   - 천둥, 아기 울음, 유리 깨지는 소리
   - 비음악적, 비언어적 청각 자극

4. 음악 (Music)
   - 기악곡, 가사 있는 음악
   - 가장 복잡하지만 강력한 감정 유발
```

---

## 3. 일반 청각 자극으로의 확장

### 3.1 확장 개연성: 높음 ✅

```
이유:

1. 선행 연구 존재
   - Cowen et al. (2018): 비언어 발성 → 24개 감정
   - Cowen et al. (2019): 음성 톤 → 12개 감정
   → Horikawa와 같은 방법론 적용 가능

2. 자극-감정 매핑이 비교적 일관됨
   - 비명 → fear (대부분 동의)
   - 웃음 → amusement (대부분 동의)
   → 비디오와 유사한 수준의 일관성

3. Transmodal 영역 가설 검증에 적합
   - 순수 청각 vs 순수 시각 비교 가능
   - 공통 영역 = Supramodal 감정 표상
```

### 3.2 고려사항

| 고려사항 | 설명 | 해결 방안 |
|:--------|:----|:---------|
| **시간 해상도** | 소리는 짧음 (1-3초), fMRI는 느림 | 반복 제시, 블록 디자인 |
| **자극 다양성** | 2000+개 확보 필요 | 기존 데이터베이스 활용 |
| **문화 차이** | 일부 발성은 문화 특수적 | 다문화 샘플, 보편적 자극 선별 |
| **강도 통제** | 음량이 감정 강도에 영향 | 음량 정규화 |

### 3.3 한계점

| 한계 | 심각도 | 설명 |
|:----|:------|:----|
| **자극 풍부성 부족** | 중간 | 비디오보다 맥락 정보 적음 |
| **혼합 감정 유발 어려움** | 중간 | 단일 소리로 복합 감정 유발 제한적 |
| **생태학적 타당성** | 낮음 | 실제 청각 경험과 유사 |

### 3.4 예상 연구 설계

```
자극: 2,000+ 청각 클립
      - 비언어 발성 (웃음, 울음, 비명 등)
      - 환경음 (천둥, 아기 울음 등)
      - 감정적 음성 톤

평정: 크라우드 소싱
      - 34개 감정 카테고리
      - 14개 정서 차원

fMRI: 5명 피험자, whole-brain

분석: Horikawa 방식 그대로
      - Decoding, Encoding, K-means
      - 비디오 연구 결과와 직접 비교
```

---

## 4. 음악 자극으로의 확장

### 4.1 확장 개연성: 중간 ⚠️

```
긍정적 요인:

1. 강력한 감정 유발
   - 음악은 "소름", "감동" 등 강한 반응 유발
   - 신호 대 잡음비 좋을 수 있음

2. 선행 연구 존재
   - Cowen et al. (2020): 음악 → 13개 감정 종류
   - fMRI 음악 연구 다수 존재

3. 비디오로 어려운 감정 접근
   - Awe, Nostalgia, Transcendence
   - 음악이 더 잘 유발하는 감정들

부정적 요인:

1. 근본적 질문들 존재 (아래 한계점 참조)
2. 개인차가 매우 큼
3. 방법론적 복잡성 높음
```

### 4.2 고려사항

| 고려사항 | 설명 | 해결 방안 |
|:--------|:----|:---------|
| **시간적 복잡성** | 음악은 시간에 따라 감정 변화 | 짧은 클립 (15-30초), 연속 평정 |
| **개인차 (전문성)** | 음악가 vs 비음악가 처리 다름 | 공변량 통제, 그룹 분리 |
| **개인차 (연상)** | 개인적 기억/연상 영향 | 새로운/익숙하지 않은 곡 사용 |
| **가사 문제** | 가사 의미가 감정에 영향 | 기악곡만 사용 |
| **문화적 차이** | 음악-감정 매핑이 문화마다 다름 | 다문화 샘플, 문화 보편적 요소 분석 |
| **장르 효과** | 장르 선호도가 감정 반응에 영향 | 다양한 장르 포함, 선호도 통제 |

### 4.3 치명적 한계점

#### 한계 1: 음악 감정 ≠ 일상 감정?

```
핵심 문제:
  음악을 들으며 느끼는 "슬픔"
  vs
  실제 상실을 겪을 때의 "슬픔"

  → 같은 신경 기제인가?

"미적 감정" (Aesthetic Emotion) 가설:
  - 음악 감정 = 실제 위협/보상 없는 "안전한" 감정
  - 일상 감정과 질적으로 다를 수 있음
  - 다른 신경 회로 관여 가능

영향:
  만약 다르다면, 음악 연구 결과를
  "감정 일반"에 일반화하기 어려움
```

#### 한계 2: 자극-감정 매핑의 비일관성

```
Horikawa 연구의 핵심 가정:
  "비디오 X를 보면 대부분 감정 Y를 느낀다"
  → 크라우드 평정 ≈ fMRI 피험자 경험

음악에서의 문제:
  "음악 X를 들으면 감정 ???"

  피아노 발라드:
    A: "결혼식 생각나" → joy
    B: "이별 노래였어" → sadness
    C: "그냥 예쁜 곡" → beauty

  → 같은 자극, 완전히 다른 감정
  → Horikawa 방법론의 핵심 가정 위반 가능
```

#### 한계 3: "감동/전율"의 분류 문제

```
음악 특유의 경험:
  - Chills/Frisson (소름)
  - Being moved (감동)
  - Transcendence (초월감)

문제:
  - 전통적 감정 카테고리 (fear, joy)에 안 맞음
  - Valence-arousal로도 설명 어려움
  - 34개 카테고리 중 어디에 해당?

영향:
  음악의 핵심 감정 경험이 기존 분류 체계에
  맞지 않으면, 비디오 연구와 비교 자체가 어려움
```

#### 한계 4: 인지-감정 분리 불가

```
음악 감상 중 동시 발생하는 처리:

  감정적: "슬프다"
  인지적: "이 화성 진행은 특이하네"
  예측적: "다음에 이 음이 올 것 같아"
  기억적: "이 멜로디 들어본 적 있어"
  운동적: "리듬에 맞춰 움직이고 싶어"

문제:
  fMRI 활성화가 순수 "감정" 때문인지,
  다른 인지 과정 때문인지 분리 어려움

영향:
  "감정의 신경 표상"이라고 주장하기 어려움
```

#### 한계 5: 생태학적 타당성 역설

```
실험 상황:
  - fMRI 스캐너 안
  - 헤드폰으로
  - 15초 클립
  - 가만히 누워서

실제 음악 경험:
  - 콘서트, 차 안, 집
  - 스피커, 라이브
  - 전체 곡/앨범
  - 춤추며, 따라 부르며

→ 실험실 음악 경험 ≠ 실제 음악 경험
→ 비디오보다 이 괴리가 더 클 수 있음
   (비디오는 원래 수동적, 음악은 종종 능동적)
```

### 4.4 예상 연구 설계 (한계를 고려한)

```
1단계: 예비 연구
  - 음악 감정이 일상 감정과 같은 신경 기제인지 검증
  - 같은 감정을 음악 vs 비음악으로 유발, 비교

2단계: 본 연구 (1단계 통과 시)
  자극: 2,000+ 기악곡 클립 (15-30초)
        - 다양한 장르, 문화권
        - 개인 연상 최소화 (새로운 곡)

  평정: 크라우드 소싱 + fMRI 피험자 본인 평정
        (개인차 문제 완화)

  참가자: 음악 전문가 / 비전문가 분리

  분석: Horikawa 방식 + 추가 통제
        - 음악적 특징 (템포, 키) 공변량으로
        - 개인별 분석 강화
```

---

## 5. 비교 요약

### 5.1 확장 개연성

| 자극 유형 | 개연성 | 이유 |
|:---------|:------|:----|
| **비언어 발성** | 높음 ✅ | 자극-감정 매핑 일관, 선행연구 풍부 |
| **환경음** | 높음 ✅ | 보편적 반응, 통제 용이 |
| **음성 톤** | 중상 ✅ | 언어 의미 통제 필요하나 가능 |
| **음악** | 중간 ⚠️ | 강력한 유발력 but 근본적 한계 |

### 5.2 고려사항 비교

| 고려사항 | 일반 청각 | 음악 |
|:--------|:---------|:----|
| 시간적 복잡성 | 낮음 | **높음** |
| 개인차 | 중간 | **매우 높음** |
| 문화 차이 | 중간 | **높음** |
| 자극 통제 | 용이 | **어려움** |
| 선행연구 | 풍부 | 풍부 |

### 5.3 한계점 비교

| 한계 | 일반 청각 | 음악 |
|:----|:---------|:----|
| 미적 감정 vs 실제 감정 | 낮음 | **심각** |
| 자극-감정 매핑 비일관성 | 낮음 | **심각** |
| 분류 체계 적합성 | 높음 | **문제적** |
| 인지-감정 분리 | 중간 | **어려움** |
| 생태학적 타당성 | 양호 | **문제적** |

---

## 6. 결론 및 제언

### 6.1 권장 확장 순서

```
1순위: 비언어 발성 + 환경음
       - Horikawa 방법론 직접 적용 가능
       - 시각 연구와 직접 비교 가능
       - "Supramodal 감정 표상" 가설 검증

2순위: 음성 톤 (Speech Prosody)
       - 언어적 의미 통제 필요
       - 사회적 감정 연구에 중요

3순위: 음악 (신중한 접근 필요)
       - 먼저 "음악 감정 = 일상 감정" 가정 검증
       - 한계점을 인정한 제한적 결론
```

### 6.2 이상적 연구 프로그램

```
Phase 1: 청각-시각 수렴 연구
┌─────────────────────────────────────────────────────────┐
│  같은 피험자에게:                                        │
│  - 무서운 비디오 (시각)                                  │
│  - 무서운 소리 (청각 - 비음악)                           │
│                                                         │
│  분석: 공통 활성화 영역 = Supramodal 감정 표상?          │
└─────────────────────────────────────────────────────────┘

Phase 2: 음악 특수성 연구
┌─────────────────────────────────────────────────────────┐
│  질문: 음악 감정은 일반 감정과 같은가?                    │
│                                                         │
│  방법: 같은 감정을 음악 vs 비음악으로 유발               │
│        신경 표상 비교                                    │
│                                                         │
│  결과에 따라:                                            │
│  - 같으면 → Phase 3로                                   │
│  - 다르면 → 음악 감정은 별개 현상으로 연구               │
└─────────────────────────────────────────────────────────┘

Phase 3: 음악 감정의 신경 표상 (Phase 2 통과 시)
┌─────────────────────────────────────────────────────────┐
│  Horikawa 방법론 적용                                    │
│  단, 한계점 명시하고 제한적 결론                         │
└─────────────────────────────────────────────────────────┘
```

### 6.3 핵심 메시지

```
일반 청각 자극 (비언어 발성, 환경음):
  → Horikawa 연구의 자연스러운 확장
  → 높은 개연성, 관리 가능한 한계
  → 적극 권장

음악 자극:
  → 매력적이지만 근본적 질문들이 있음
  → "음악 감정 = 일상 감정" 가정 먼저 검증 필요
  → 신중한 접근, 한계 인정 필수
  → 조건부 권장
```

---

## 참고 문헌

- Horikawa et al. (2020). The Neural Representation of Visually Evoked Emotion. *iScience*.
- Cowen & Keltner (2017). Self-report captures 27 distinct categories of emotion. *PNAS*.
- Cowen et al. (2018). Mapping 24 emotions conveyed by brief human vocalization. *American Psychologist*.
- Cowen et al. (2019). The primacy of categories in the recognition of 12 emotions in speech prosody. *Nature Human Behaviour*.
- Cowen et al. (2020). What music makes us feel: At least 13 dimensions organize subjective experiences associated with music. *PNAS*.

---

*작성일: 2026-01-05*
*Horikawa (2020) 논문 학습 노트의 일부로 작성*
