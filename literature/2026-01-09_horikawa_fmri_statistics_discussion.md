# Horikawa et al. (2020) fMRI 통계 방법론 정리

**날짜**: 2026-01-09
**참고 자료**: horikawa_sm.pdf (Supplementary Materials)

---

## 목차

1. [실험 디자인 요약](#1-실험-디자인-요약)
2. [다중 비교 문제 (Multiple Comparisons Problem)](#2-다중-비교-문제)
3. [Permutation Test](#3-permutation-test)
4. [FDR (False Discovery Rate)](#4-fdr-false-discovery-rate)
5. [r > 0.095 기준의 의미](#5-r--0095-기준의-의미)
6. [낮은 상관계수(r)의 해석: SNR과의 관계](#6-낮은-상관계수의-해석-snr과의-관계)
7. [p < 0.01 vs p < 0.05](#7-p--001-vs-p--005)
8. [Ensemble Decoder](#8-ensemble-decoder)
9. [핵심 교훈](#9-핵심-교훈)

---

## 1. 실험 디자인 요약

### 1.1 피험자

| 피험자 | 성별 | 나이 |
|--------|------|------|
| Subject 1 | 남성 | 34세 |
| Subject 2 | 남성 | 23세 |
| Subject 3 | 여성 | 23세 |
| Subject 4 | 남성 | 22세 |
| Subject 5 | 남성 | 27세 |

### 1.2 자극

- **출처**: Cowen & Keltner (2017) 비디오 데이터셋
- **총 개수**: 2,196개 → 2,181개 (중복 제거 후)
- **길이**: ~0.15초 ~ ~90초
- **제시 방식**: 무음(no sound), 회색 배경, 자유 시선 허용

### 1.3 실험 구조

```
총 61개 런 (runs)
├── 각 런: 36개 자극 블록
├── 블록 규칙:
│   ├── 비디오 < 8초: 반복 재생하여 8초 이상 채움
│   └── 비디오 > 8초: 1회 재생 + ~2초 휴식
├── 런 길이: 7분 10초 ~ 9분 54초
└── 총 스캔 시간: 약 8시간/피험자
```

### 1.4 MRI 파라미터

| 파라미터 | 값 |
|----------|-----|
| 스캐너 | 3.0-Tesla Siemens MAGNETOM Verio |
| TR | 2,000 ms |
| TE | 43 ms |
| Voxel size | 2 × 2 × 2 mm |
| 슬라이스 수 | 76개 |
| Multiband factor | 4 |

### 1.5 비디오 레이블링

| 유형 | 개수 | 수집 방식 |
|------|------|-----------|
| 감정 카테고리 | 34개 | 100점 척도 → 이진화 |
| 정서 차원 | 14개 | 9점 Likert 척도 |
| 시각적 객체 피처 | 1,000개 | VGG19 DNN fc8 layer |
| 의미적 피처 | 73개 | AMT에서 yes/no 평가 |

---

## 2. 다중 비교 문제

### 2.1 문제의 본질

fMRI에서 whole-brain 분석 시:
- Voxel 수: 약 150,000개 이상
- 유의수준 α = 0.05 사용 시:
  - 기대되는 거짓 양성 수 = 150,000 × 0.05 = **7,500개**
  - 실제 효과가 없어도 수천 개 복셀이 "유의"하게 나옴

### 2.2 해결책 비교

| 방법 | 통제 대상 | 특징 |
|------|-----------|------|
| **Bonferroni** | 하나라도 거짓 양성 있을 확률 (FWER) | 매우 보수적 |
| **FDR** | 거짓 양성의 비율 | 덜 보수적, 탐색적 연구에 적합 |
| **Cluster-level** | 복셀 덩어리 단위 검정 | 해부학적으로 의미있는 결과 |

### 2.3 Horikawa 연구의 선택

- **Bonferroni 보정** 사용
- 뇌 영역 수 n = 370에 대해 보정
- 기준: p < 0.01 / 370 = 0.000027

---

## 3. Permutation Test

### 3.1 핵심 아이디어

**귀무가설(H₀)**: "관찰된 관계는 우연이다"

이 가설이 참일 때의 분포를 **데이터를 직접 섞어서** 만든다.

### 3.2 절차

```
Step 1: 실제 데이터로 상관계수 계산 (예: r = 0.35)

Step 2: 라벨을 무작위로 섞음 (진짜 관계를 끊음)
        → 섞은 상태에서 상관계수 계산

Step 3: Step 2를 수천~수만 번 반복
        → Null distribution 완성

Step 4: p-value = (null에서 |r| ≥ 0.35인 비율)

Step 5: 해석
        - p가 작다 = "우연으로는 이런 값이 안 나온다"
        - → "우연이 아니다" = "진짜 관계가 있다"
```

### 3.3 Horikawa 연구에서의 적용

> "null distributions of correlations between two independent Gaussian random vectors of the same length (2181 elements, **n = 100,000,000,000**)"

- 1000억 번의 시뮬레이션으로 null distribution 생성
- 분포 가정 없이 p-value 계산 가능

### 3.4 핵심 논리 (자주 혼동되는 부분)

```
잘못된 해석:
"10,000번 중 23번만 r ≥ 0.35" → "r = 0.35가 나오기 어렵다" → "내 결과가 의심스럽다"

올바른 해석:
"10,000번 중 23번만 r ≥ 0.35" → "관계가 없으면 이런 값이 안 나온다" → "관계가 있다!"
```

---

## 4. FDR (False Discovery Rate)

### 4.1 Bonferroni vs FDR

| 측면 | Bonferroni | FDR |
|------|------------|-----|
| 통제 대상 | 1개라도 거짓 양성 있을 확률 | 거짓 양성의 **비율** |
| 엄격함 | 매우 엄격 | 덜 엄격 |
| 검정력 | 낮음 (진짜를 놓침) | 높음 (진짜를 잘 찾음) |
| 적합한 상황 | 거짓 양성이 치명적일 때 | 탐색적 연구 |

### 4.2 Benjamini-Hochberg 절차

1. 모든 p-value를 작은 순서로 정렬
2. 각 순위(i)에 대해 임계값 계산: `(i / m) × q` (m = 총 검정 수, q = 목표 FDR)
3. p-value ≤ 임계값인 가장 큰 순위 찾기
4. 그 순위까지의 모든 결과를 "유의"로 선언

### 4.3 예시

```
목표 FDR = 0.05, 총 검정 수 = 100,000

순위 2500에서 p-value = 임계값을 만족한다면:
→ 순위 1~2500까지 유의
→ 이 중 약 5% (125개)는 거짓 양성일 수 있음
→ 하지만 2375개는 진짜!
```

---

## 5. r > 0.095 기준의 의미

### 5.1 문장 해석

> "r > 0.095 (permutation test, p < 0.01, Bonferroni corrected)"

```
의미:
1. Permutation test로 null distribution 생성
2. 370개 영역에 대한 Bonferroni 보정 적용
3. 보정 후 p < 0.01이 되는 최소 r 값 = 0.095
4. r > 0.095인 영역만 ensemble에 포함
```

### 5.2 계산 과정

```
목표 p-value: 0.01
다중비교 보정: 0.01 / 370 = 0.000027

Null distribution에서 상위 0.000027%에 해당하는 r 값 = 0.095
```

### 5.3 적용

```
영역         디코딩 r    r > 0.095?    Ensemble 포함?
─────────────────────────────────────────────────────
시각피질 V1    0.12        ✅             포함
편도체         0.15        ✅             포함
TPJ            0.08        ❌             제외
해마           0.04        ❌             제외
```

---

## 6. 낮은 상관계수의 해석: SNR과의 관계

### 6.1 r = 0.095가 낮아 보이는데 의미있는 이유

#### 샘플 크기 효과

```
n = 2,181에서 r = 0.095:
t ≈ 4.46, p < 0.00001

같은 r = 0.095라도:
- n = 30: p = 0.62 (유의하지 않음)
- n = 2,181: p < 0.00001 (유의함)
```

#### fMRI의 본질적 한계

```
신경 활동 → 혈류 변화 → BOLD 신호 → 측정값

각 단계에서 노이즈 추가 + 신호 희석
→ 원래 효과가 있어도 관찰되는 r이 낮아짐
```

### 6.2 tSNR (Temporal Signal-to-Noise Ratio)

```
tSNR = 평균(신호) / 표준편차(신호)

일반적인 fMRI tSNR: 20-50 (상당히 낮음)

비교:
- 디지털 카메라: SNR > 1000
- 좋은 오디오: SNR > 100
- fMRI: SNR ≈ 20-50
```

### 6.3 감쇠 효과 (Attenuation)

```
관찰된 r = 진짜 r × √(신뢰도_X) × √(신뢰도_Y)

예: 진짜 r = 0.5, tSNR = 30, 감정 평가 신뢰도 = 0.8
→ 관찰된 r ≈ 0.44 (12% 감소)
```

### 6.4 r = 0.08의 평가

| 관점 | 평가 |
|------|------|
| 통계적 유의성 | n=2181에서 p ≈ 0.0002 (유의함) |
| Horikawa 기준 | r < 0.095이므로 제외됨 |
| Cohen의 기준 | "작은 효과"에도 못 미침 |
| 설명력 (R²) | 0.64%만 설명 |

**결론**: 통계적으로 유의할 수 있지만, 단독으로는 실질적 의미가 제한적. 다른 증거들과 종합해야 의미있음.

---

## 7. p < 0.01 vs p < 0.05

### 7.1 p < 0.05의 기원

- 1925년 Fisher가 "편리한 관례"로 제안
- 절대적 진리가 아닌 역사적 관습

### 7.2 Horikawa가 p < 0.01을 선택한 이유

1. **다중비교의 규모가 큼**: 370개 영역 × 48개 감정
2. **신경과학의 관례**: 엄격한 기준 선호 추세
3. **재현성 위기 대응**: p < 0.05가 너무 관대하다는 비판
4. **2017년 제안**: 72명의 통계학자들이 p < 0.005 권장

### 7.3 Trade-off

```
엄격한 기준 (p < 0.01):
✓ 거짓 양성 ↓
✗ 거짓 음성 ↑ (진짜를 놓칠 위험)

관대한 기준 (p < 0.05):
✗ 거짓 양성 ↑
✓ 거짓 음성 ↓
```

---

## 8. Ensemble Decoder

### 8.1 정의

여러 뇌 영역의 디코더 예측을 합쳐서 하나의 더 좋은 예측을 만드는 방법

### 8.2 구조

```
뇌 활동 데이터
     │
     ├──→ [영역 1 디코더] ──→ 예측값 1
     ├──→ [영역 2 디코더] ──→ 예측값 2
     ├──→ [영역 3 디코더] ──→ 예측값 3
     └──→ [영역 4 디코더] ──→ (r < 0.095, 제외)
                │
                ▼
         평균 (Ensemble 예측)
```

### 8.3 왜 Ensemble이 더 좋은가?

1. **노이즈 상쇄**: 각 영역의 노이즈가 서로 상쇄
2. **상보적 정보**: 각 영역이 감정의 다른 측면 담당
3. **수학적 원리**: 노이즈 표준편차 ∝ 1/√n

### 8.4 성능 향상

```
개별 영역: r = 0.08 ~ 0.30 (대부분 낮음)
          ↓
     Ensemble로 합침
          ↓
비디오 식별: 70~80% 정확도 (우연 = 50%)
```

### 8.5 선별이 필요한 이유

```
모든 370개 영역 사용 시:
- 노이즈만 있는 영역이 좋은 신호를 희석
- 전체 성능 저하

선별 (r > 0.095) 후:
- 진짜 신호가 있는 영역만 포함
- 최적의 성능
```

---

## 9. 핵심 교훈

### 9.1 통계적 유의성 ≠ 실질적 의미

```
"유의하다" ≠ "중요하다" ≠ "의미있다"

통계적 유의성: "우연인가 아닌가?"
효과 크기:     "얼마나 큰 효과인가?"
실질적 의미:   "실제로 쓸모가 있는가?"
```

### 9.2 다중비교 보정의 중요성

- 많은 검정 → 거짓 양성 급증
- Bonferroni/FDR로 보정 필수
- 연구 맥락에 맞는 방법 선택

### 9.3 fMRI 데이터의 특성

- 낮은 SNR → 낮은 관찰 r
- 낮은 r이라도 무의미하지 않을 수 있음
- Ensemble로 약한 신호들을 종합

### 9.4 p-value의 한계

- p < 0.05는 마법의 숫자가 아님
- 효과 크기와 맥락을 함께 고려
- 재현성 위기 이후 더 엄격한 기준 권장

---

## 참고 문헌

- Horikawa, T., Cowen, A. S., Keltner, D., & Kamitani, Y. (2020). The Neural Representation of Visually Evoked Emotion Is High-Dimensional, Categorical, and Distributed across Transmodal Brain Regions. *iScience*, 23(5).
- Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences.
- Benjamin, D. J., et al. (2018). Redefine statistical significance. *Nature Human Behaviour*.

---

*작성: 2026-01-09*
